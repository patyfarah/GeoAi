{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/patyfarah/GeoAi/blob/main/AI_proj.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XtzZvXnzvuGB",
      "metadata": {
        "id": "XtzZvXnzvuGB"
      },
      "source": [
        "# Connect to Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "V1Miy6wox9FL",
      "metadata": {
        "id": "V1Miy6wox9FL"
      },
      "source": [
        "10sM4wqtNGndS7qqXspHw28mMfoFp-pl7\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1751cd32",
      "metadata": {
        "id": "1751cd32",
        "outputId": "2ca943b8-0216-4719-c0e3-eed75b5136be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to retrieve file url:\n",
            "\n",
            "\tToo many users have viewed or downloaded this file recently. Please\n",
            "\ttry accessing the file again later. If the file you are trying to\n",
            "\taccess is particularly large or is shared with many people, it may\n",
            "\ttake up to 24 hours to be able to view or download the file. If you\n",
            "\tstill can't access a file after 24 hours, contact your domain\n",
            "\tadministrator.\n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\thttps://drive.google.com/uc?id=10sM4wqtNGndS7qqXspHw28mMfoFp-pl7\n",
            "\n",
            "but Gdown can't. Please check connections and permissions.\n"
          ]
        }
      ],
      "source": [
        "!gdown 10sM4wqtNGndS7qqXspHw28mMfoFp-pl7 -O '/content/University1652.zip'"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xKWjMfIo5U59"
      },
      "id": "xKWjMfIo5U59",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Hg9IjZFatdHh",
      "metadata": {
        "id": "Hg9IjZFatdHh"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile('/content/University1652.zip', 'r') as zip_ref:\n",
        "    # Extract the contents to the /content/ directory\n",
        "    zip_ref.extractall('/content/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9ONFpirZeWl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9ONFpirZeWl",
        "outputId": "e44f7f9b-fa80-4857-b95c-5964ff3c209d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MLPN_workshop'...\n",
            "remote: Enumerating objects: 38, done.\u001b[K\n",
            "remote: Counting objects: 100% (38/38), done.\u001b[K\n",
            "remote: Compressing objects: 100% (36/36), done.\u001b[K\n",
            "remote: Total 38 (delta 4), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (38/38), 3.85 MiB | 7.50 MiB/s, done.\n",
            "Resolving deltas: 100% (4/4), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/HrLi97/MLPN_workshop.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uYJjCN4WqIVf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYJjCN4WqIVf",
        "outputId": "89ee88f6-1b9e-4f30-881d-4461b8a17728"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1dZ9itDjS-h5KHc23OQb8oHqJ3KoSaPyS\n",
            "From (redirected): https://drive.google.com/uc?id=1dZ9itDjS-h5KHc23OQb8oHqJ3KoSaPyS&confirm=t&uuid=277c6feb-2c9c-40bc-ba15-8691f7fd47f3\n",
            "To: /content/pretrained.zip\n",
            "100% 1.63G/1.63G [00:18<00:00, 87.3MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 1dZ9itDjS-h5KHc23OQb8oHqJ3KoSaPyS -O '/content/pretrained.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bri2iNeqbKW",
      "metadata": {
        "id": "6bri2iNeqbKW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "6eaf707e-92c5-4350-ba27-feac67e98c71"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/pretrained.zip'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-688679579c6b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/pretrained.zip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Extract the contents to the /content/ directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[1;32m   1293\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/pretrained.zip'"
          ]
        }
      ],
      "source": [
        "with zipfile.ZipFile('/content/pretrained.zip', 'r') as zip_ref:\n",
        "    # Extract the contents to the /content/ directory\n",
        "    zip_ref.extractall('/content/')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Yt9CvVqD92rb",
      "metadata": {
        "id": "Yt9CvVqD92rb"
      },
      "source": [
        "# Test Model 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JHhHGgx991nr",
      "metadata": {
        "id": "JHhHGgx991nr"
      },
      "outputs": [],
      "source": [
        "#print model\n",
        "!python /content/MLPN_workshop/model.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Fd_ksNMoxAj8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fd_ksNMoxAj8",
        "outputId": "98825b61-34fb-4b8f-8659-99d01958176e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement python-parser (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for python-parser\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Tsl0f5ux_A-M",
      "metadata": {
        "id": "Tsl0f5ux_A-M"
      },
      "outputs": [],
      "source": [
        "!python /content/MLPN_workshop/utils.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Zci9suiV-FzY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zci9suiV-FzY",
        "outputId": "359620d3-0e85-4298-f306-d76558d0e9e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This is not an error. If you want to use low precision, i.e., fp16, please install the apex with cuda support (https://github.com/NVIDIA/apex) and update pytorch to 1.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.11\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory. Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
            "random seed---------------------: 0\n",
            "---------------Pool Strategy------------: avg\n",
            "[Resize(size=(256, 256), interpolation=bicubic, max_size=None, antialias=True), Pad(padding=10, fill=0, padding_mode=edge), RandomCrop(size=(256, 256), padding=None), RandomHorizontalFlip(p=0.5), ToTensor(), Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "{'satellite': 701, 'drone': 37854}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/MLPN_workshop/train_info.py\", line 258, in <module>\n",
            "    test_imgDatasets = {x: datasets.ImageFolder(os.path.join(test_dir, x), data_transforms['val']) for x in\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/MLPN_workshop/train_info.py\", line 258, in <dictcomp>\n",
            "    test_imgDatasets = {x: datasets.ImageFolder(os.path.join(test_dir, x), data_transforms['val']) for x in\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\", line 328, in __init__\n",
            "    super().__init__(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\", line 149, in __init__\n",
            "    classes, class_to_idx = self.find_classes(self.root)\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\", line 234, in find_classes\n",
            "    return find_classes(directory)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\", line 41, in find_classes\n",
            "    classes = sorted(entry.name for entry in os.scandir(directory) if entry.is_dir())\n",
            "                                             ^^^^^^^^^^^^^^^^^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/home/lihaoran/BJDD_datesets/datesets/University-Release/test/gallery_satellite'\n",
            "\u001b[1;34mwandb\u001b[0m: \n",
            "\u001b[1;34mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[1;34mwandb\u001b[0m: \u001b[1mwandb sync /content/wandb/offline-run-20250606_202656-j6144ku3\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/offline-run-20250606_202656-j6144ku3/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python /content/MLPN_workshop/train_info.py"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0CIR_wa4LOZF",
      "metadata": {
        "id": "0CIR_wa4LOZF"
      },
      "source": [
        "#Test Model 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RREcJ4d0LQbl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "RREcJ4d0LQbl",
        "outputId": "f58079b3-fd70-4194-8b1c-55d21c1549fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'WELN'...\n",
            "remote: Enumerating objects: 31, done.\u001b[K\n",
            "remote: Counting objects: 100% (31/31), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 31 (delta 8), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (31/31), 26.55 KiB | 8.85 MiB/s, done.\n",
            "Resolving deltas: 100% (8/8), done.\n"
          ]
        }
      ],
      "source": [
        "# download code\n",
        "!git clone https://github.com/koorter/WELN.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd WELN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61w7djHx4BqY",
        "outputId": "d8497dc1-a3b8-436a-c8b8-7459e37eede9"
      },
      "id": "61w7djHx4BqY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/WELN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.2.2+cu121 torchvision==0.17.2+cu121 \\\n",
        "            --extra-index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install timm pytorch_metric_learning scikit-learn pyyaml tqdm pillow opencv-python\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9X5E4-d4G6I",
        "outputId": "d9fd0105-c61a-4593-e3af-bcab4089d2ce"
      },
      "id": "s9X5E4-d4G6I",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu121\n",
            "Collecting torch==2.2.2+cu121\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torch-2.2.2%2Bcu121-cp311-cp311-linux_x86_64.whl (757.3 MB)\n",
            "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.6/757.3 MB\u001b[0m \u001b[31m100.0 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.15)\n",
            "Collecting pytorch_metric_learning\n",
            "  Downloading pytorch_metric_learning-2.8.1-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (6.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from timm) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm) (0.21.0+cu124)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.32.4)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pytorch_metric_learning) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->timm) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->timm)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->timm)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->timm)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->timm)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->timm)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->timm)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->timm)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->timm)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->timm)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->timm)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (1.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->timm) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2025.4.26)\n",
            "Downloading pytorch_metric_learning-2.8.1-py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.9/125.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m318.0/363.4 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m318.0/363.4 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -c \"import yaml, pprint, pathlib, sys; d=yaml.safe_load(open('settings.yaml')); pprint.pprint(d)\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FVsVpkW7KF7",
        "outputId": "e32d2466-cad8-4d6a-8413-aaf69c09619d"
      },
      "id": "0FVsVpkW7KF7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'LPN': 0,\n",
            " 'batch_size': 8,\n",
            " 'block': 4,\n",
            " 'classes': 701,\n",
            " 'dataset_path': '/media/sues/daa8aa38-6c2b-4fb6-a66f-327e4fc2f6a6/dataset/university_plus/train',\n",
            " 'drop_rate': 0.4,\n",
            " 'fp16': 0,\n",
            " 'image_size': 448,\n",
            " 'lr': 0.0005,\n",
            " 'model': 'eva02mim',\n",
            " 'name': 'eva02_L_1652_2024-06-18-21:49:21',\n",
            " 'num_epochs': 80,\n",
            " 'query': 'drone',\n",
            " 'share_weight': True,\n",
            " 'weight_decay': 0.0001,\n",
            " 'weight_save_path': 'weights'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -d /content/University-Release/train/satellite  /content/University-Release/train/drone\n",
        "!ls /content/University-Release/train/satellite | head\n",
        "!ls /content/University-Release/train/drone | head\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hloXpY7b8d7Q",
        "outputId": "62cb65a0-cc1e-4e46-d223-a3992a34c702"
      },
      "id": "hloXpY7b8d7Q",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/content/University-Release/train/satellite': No such file or directory\n",
            "ls: cannot access '/content/University-Release/train/drone': No such file or directory\n",
            "ls: cannot access '/content/University-Release/train/satellite': No such file or directory\n",
            "ls: cannot access '/content/University-Release/train/drone': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) uninstall the pieces that are fighting\n",
        "!pip uninstall -y numpy scikit-learn numba tensorflow sklearn-compat opencv-python\n",
        "\n",
        "# 2) reinstall with compatible pins\n",
        "!pip install \"numpy==1.26.4\"               \\\n",
        "            \"numba>=0.58,<0.60\"           \\\n",
        "            \"tensorflow~=2.15.0\"          \\\n",
        "            \"scikit-learn~=1.6.1\"         \\\n",
        "            \"sklearn-compat~=0.1.3\"       \\\n",
        "            \"opencv-python~=4.11.0.86\"\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auUkv1IN80rn",
        "outputId": "88f71f2f-80a0-46d1-da49-c6ee2ebda91f"
      },
      "id": "auUkv1IN80rn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 2.0.2\n",
            "Uninstalling numpy-2.0.2:\n",
            "  Successfully uninstalled numpy-2.0.2\n",
            "Found existing installation: scikit-learn 1.6.1\n",
            "Uninstalling scikit-learn-1.6.1:\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/commands/install.py\", line 324, in run\n",
            "    session = self.get_default_session(options)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/index_command.py\", line 71, in get_default_session\n",
            "    self._session = self.enter_context(self._build_session(options))\n",
            "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/index_command.py\", line 100, in _build_session\n",
            "    session = PipSession(\n",
            "              ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/network/session.py\", line 344, in __init__\n",
            "    self.headers[\"User-Agent\"] = user_agent()\n",
            "                                 ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/network/session.py\", line 177, in user_agent\n",
            "    setuptools_dist = get_default_environment().get_distribution(\"setuptools\")\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/metadata/importlib/_envs.py\", line 189, in get_distribution\n",
            "    return next(matches, None)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/metadata/importlib/_envs.py\", line 184, in <genexpr>\n",
            "    matches = (\n",
            "              ^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/metadata/base.py\", line 612, in iter_all_distributions\n",
            "    for dist in self._iter_distributions():\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/metadata/importlib/_envs.py\", line 177, in _iter_distributions\n",
            "    for dist in finder.find_eggs(location):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/metadata/importlib/_envs.py\", line 144, in find_eggs\n",
            "    yield from self._find_eggs_in_dir(location)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/metadata/importlib/_envs.py\", line 111, in _find_eggs_in_dir\n",
            "    from pip._vendor.pkg_resources import find_distributions\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3291, in <module>\n",
            "    @_call_aside\n",
            "     ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3266, in _call_aside\n",
            "    f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3304, in _initialize_master_working_set\n",
            "    working_set = WorkingSet._build_master()\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 591, in _build_master\n",
            "    ws = cls()\n",
            "         ^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 584, in __init__\n",
            "    self.add_entry(entry)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 641, in add_entry\n",
            "    self.add(dist, entry, False)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 734, in add\n",
            "    normalized_name = packaging.utils.canonicalize_name(dist.key)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/packaging/utils.py\", line 49, in canonicalize_name\n",
            "    value = _canonicalize_regex.sub(\"-\", name).lower()\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1742, in isEnabledFor\n",
            "    return self._cache[level]\n",
            "           ~~~~~~~~~~~^^^^^^^\n",
            "KeyError: 50\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n",
            "    return command.main(cmd_args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n",
            "    return self._main(args)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n",
            "    return run(options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 215, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1535, in critical\n",
            "    if self.isEnabledFor(CRITICAL):\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1746, in isEnabledFor\n",
            "    if self.manager.disable >= level:\n",
            "       ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1319, in disable\n",
            "    @property\n",
            "\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -d /content/University-Release/train/{satellite,drone}\n",
        "!ls /content/University-Release/train/satellite | head\n",
        "!ls /content/University-Release/train/drone | head\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBmzYwDFpPhm",
        "outputId": "b1b516c6-9b75-4bd7-f5bf-1709eae36a39"
      },
      "id": "CBmzYwDFpPhm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/content/University-Release/train/satellite': No such file or directory\n",
            "ls: cannot access '/content/University-Release/train/drone': No such file or directory\n",
            "ls: cannot access '/content/University-Release/train/satellite': No such file or directory\n",
            "ls: cannot access '/content/University-Release/train/drone': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7NkCG0DyLsQ1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7NkCG0DyLsQ1",
        "outputId": "6e48788b-20ff-4019-ab2a-da90442c0f73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/_subclasses/functional_tensor.py:275: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:81.)\n",
            "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/WELN/train_1652plus_n.py\", line 11, in <module>\n",
            "    from torchvision import datasets, transforms\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/__init__.py\", line 10, in <module>\n",
            "    from torchvision import _meta_registrations, datasets, io, models, ops, transforms, utils  # usort:skip\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/datasets/__init__.py\", line 1, in <module>\n",
            "    from ._optical_flow import FlyingChairs, FlyingThings3D, HD1K, KittiFlow, Sintel\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/datasets/_optical_flow.py\", line 8, in <module>\n",
            "    import numpy as np\n",
            "ModuleNotFoundError: No module named 'numpy'\n"
          ]
        }
      ],
      "source": [
        "!python /content/WELN/train_1652plus_n.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "no84I_6bMM-z",
      "metadata": {
        "collapsed": true,
        "id": "no84I_6bMM-z"
      },
      "outputs": [],
      "source": [
        "!python /content/WELN/utils.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VQrQdsteMS4M",
      "metadata": {
        "collapsed": true,
        "id": "VQrQdsteMS4M"
      },
      "outputs": [],
      "source": [
        "!pip install pytorch_metric_learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Th5li6WCNL9t",
      "metadata": {
        "id": "Th5li6WCNL9t"
      },
      "outputs": [],
      "source": [
        "# run settings.yaml\n",
        "import yaml\n",
        "\n",
        "with open('/content/WELN/settings.yaml', 'r') as file:\n",
        "  yaml_data = yaml.safe_load(file)\n",
        "print(yaml_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pL0l8k3WVLT1",
      "metadata": {
        "id": "pL0l8k3WVLT1"
      },
      "outputs": [],
      "source": [
        "!pip install apex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "D2m5jfTMmqky",
      "metadata": {
        "id": "D2m5jfTMmqky"
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "\n",
        "with open('/content/WELN/settings.yaml', 'r') as file:\n",
        "  yaml_data = yaml.safe_load(file)\n",
        "print(yaml_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OBBd4xp4ncIZ",
      "metadata": {
        "id": "OBBd4xp4ncIZ"
      },
      "outputs": [],
      "source": [
        "!mkdir -p /content/weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jZEzlu3sCi-0",
      "metadata": {
        "id": "jZEzlu3sCi-0"
      },
      "outputs": [],
      "source": [
        "%%writefile /content/settings.yaml\n",
        "# example keys – edit to match your project\n",
        "LPN: true\n",
        "name: default_run\n",
        "data_dir: /content/data/U1652/University-Release\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Sf2yI1qICqvf",
      "metadata": {
        "id": "Sf2yI1qICqvf"
      },
      "outputs": [],
      "source": [
        "%cd /content            # same directory that holds settings.yaml\n",
        "!python /content/WELN/train_1652plus_n.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9_-MS2OdLzuc",
      "metadata": {
        "id": "9_-MS2OdLzuc"
      },
      "outputs": [],
      "source": [
        "!python /content/WELN/utils.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lg6bnCAnJNKI",
      "metadata": {
        "id": "lg6bnCAnJNKI"
      },
      "outputs": [],
      "source": [
        "pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" apex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AduON6vqJU2v",
      "metadata": {
        "id": "AduON6vqJU2v"
      },
      "outputs": [],
      "source": [
        "pip install pytorch_metric_learning tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SWMZZxcgJb09",
      "metadata": {
        "id": "SWMZZxcgJb09"
      },
      "outputs": [],
      "source": [
        "# install gdown once\n",
        "!pip install -q gdown\n",
        "\n",
        "# 1) download – official file-id from the paper’s link\n",
        "!gdown --id 1iVnP4gjw-iHXa0KerZQ1IfIO0i1jADsR -O University1652.zip\n",
        "\n",
        "# 2) unzip\n",
        "!unzip -q University1652.zip -d /content/\n",
        "\n",
        "# 3) flatten so we have exactly /content/University1652/{satellite,drone}\n",
        "!mv /content/University-1652/train /content/University1652\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2XvfQJXHF1xi",
      "metadata": {
        "id": "2XvfQJXHF1xi"
      },
      "outputs": [],
      "source": [
        "!python /content/WELN/train_1652plus_n.py"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EuqgGPA7qUAp",
      "metadata": {
        "id": "EuqgGPA7qUAp"
      },
      "source": [
        "# Model Test 3 (Paty Farah Contribution)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#download folder\n",
        "!git clone https://github.com/Skyy93/Sample4Geo.git"
      ],
      "metadata": {
        "id": "fxG2moIw3Iwj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20d771be-5e23-4628-ae1c-e44a03a195af"
      },
      "id": "fxG2moIw3Iwj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Sample4Geo'...\n",
            "remote: Enumerating objects: 116, done.\u001b[K\n",
            "remote: Counting objects: 100% (42/42), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 116 (delta 32), reused 27 (delta 27), pack-reused 74 (from 1)\u001b[K\n",
            "Receiving objects: 100% (116/116), 772.00 KiB | 3.37 MiB/s, done.\n",
            "Resolving deltas: 100% (69/69), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup Requirements\n",
        "# 1) uninstall the pieces that are fighting\n",
        "!pip uninstall -y torch timm scipy albumentations scikit-learn transformers pandas tqdm\n",
        "\n",
        "# 2) reinstall with compatible pins\n",
        "!pip install \"torch>=1.13.1\" \\\n",
        "            \"timm>=0.8.8\" \\\n",
        "            \"scipy>=1.10.0\" \\\n",
        "            \"albumentations>=1.3.0\" \\\n",
        "            \"scikit-learn>=1.2.1\" \\\n",
        "            \"transformers>=4.27.0\" \\\n",
        "            \"pandas\" \\\n",
        "            \"tqdm\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGR2cLhLEclw",
        "outputId": "f4c1a3d0-95c1-4300-a524-f8857b830c36"
      },
      "id": "pGR2cLhLEclw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.6.0+cu124\n",
            "Uninstalling torch-2.6.0+cu124:\n",
            "  Successfully uninstalled torch-2.6.0+cu124\n",
            "Found existing installation: timm 1.0.15\n",
            "Uninstalling timm-1.0.15:\n",
            "  Successfully uninstalled timm-1.0.15\n",
            "Found existing installation: scipy 1.15.3\n",
            "Uninstalling scipy-1.15.3:\n",
            "  Successfully uninstalled scipy-1.15.3\n",
            "Found existing installation: albumentations 2.0.8\n",
            "Uninstalling albumentations-2.0.8:\n",
            "  Successfully uninstalled albumentations-2.0.8\n",
            "Found existing installation: scikit-learn 1.6.1\n",
            "Uninstalling scikit-learn-1.6.1:\n",
            "  Successfully uninstalled scikit-learn-1.6.1\n",
            "Found existing installation: transformers 4.52.4\n",
            "Uninstalling transformers-4.52.4:\n",
            "  Successfully uninstalled transformers-4.52.4\n",
            "Found existing installation: pandas 2.2.2\n",
            "Uninstalling pandas-2.2.2:\n",
            "  Successfully uninstalled pandas-2.2.2\n",
            "Found existing installation: tqdm 4.67.1\n",
            "Uninstalling tqdm-4.67.1:\n",
            "  Successfully uninstalled tqdm-4.67.1\n",
            "Collecting torch>=1.13.1\n",
            "  Downloading torch-2.7.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
            "Collecting timm>=0.8.8\n",
            "  Downloading timm-1.0.15-py3-none-any.whl.metadata (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.0/52.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy>=1.10.0\n",
            "  Downloading scipy-1.15.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting albumentations>=1.3.0\n",
            "  Downloading albumentations-2.0.8-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.1/43.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn>=1.2.1\n",
            "  Downloading scikit_learn-1.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (17 kB)\n",
            "Collecting transformers>=4.27.0\n",
            "  Downloading transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting pandas\n",
            "  Downloading pandas-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1) (4.14.0)\n",
            "Collecting sympy>=1.13.3 (from torch>=1.13.1)\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch>=1.13.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch>=1.13.1)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch>=1.13.1)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch>=1.13.1)\n",
            "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch>=1.13.1)\n",
            "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch>=1.13.1)\n",
            "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.7.77 (from torch>=1.13.1)\n",
            "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch>=1.13.1)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch>=1.13.1)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch>=1.13.1)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.26.2 (from torch>=1.13.1)\n",
            "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.6.77 (from torch>=1.13.1)\n",
            "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch>=1.13.1)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch>=1.13.1)\n",
            "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.3.1 (from torch>=1.13.1)\n",
            "  Downloading triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.1->torch>=1.13.1) (75.2.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm>=0.8.8) (0.21.0+cu124)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm>=0.8.8) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm>=0.8.8) (0.32.4)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm>=0.8.8) (0.5.3)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy>=1.10.0) (2.0.2)\n",
            "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.11/dist-packages (from albumentations>=1.3.0) (2.11.5)\n",
            "Requirement already satisfied: albucore==0.0.24 in /usr/local/lib/python3.11/dist-packages (from albumentations>=1.3.0) (0.0.24)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.11/dist-packages (from albumentations>=1.3.0) (4.11.0.86)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.24->albumentations>=1.3.0) (3.12.5)\n",
            "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.24->albumentations>=1.3.0) (6.4.7)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.1) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.1) (3.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.27.0) (24.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.27.0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers>=4.27.0) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.27.0) (0.21.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm>=0.8.8) (1.1.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations>=1.3.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations>=1.3.0) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations>=1.3.0) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch>=1.13.1) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.1) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.27.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.27.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.27.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.27.0) (2025.4.26)\n",
            "Collecting torch>=1.13.1\n",
            "  Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->timm>=0.8.8) (11.2.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.13.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.13.1)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.13.1)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13.1)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12 (from nvidia-cudnn-cu12==9.5.1.17->torch>=1.13.1)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.13.1)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.13.1)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.13.1)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12 (from nvidia-cusolver-cu12==11.7.1.2->torch>=1.13.1)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cufft-cu12==11.3.0.4->torch>=1.13.1)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1) (1.13.1)\n",
            "Downloading timm-1.0.15-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m97.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.15.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.7/37.7 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading albumentations-2.0.8-py3-none-any.whl (369 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m369.4/369.4 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.52.4-py3-none-any.whl (10.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m101.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m99.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m815.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m100.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m98.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m102.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tqdm, scipy, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, scikit-learn, pandas, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, albumentations, transformers, torch, timm\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.0 which is incompatible.\n",
            "sklearn-compat 0.1.3 requires scikit-learn<1.7,>=1.2, but you have scikit-learn 1.7.0 which is incompatible.\n",
            "cudf-cu12 25.2.1 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.0 which is incompatible.\n",
            "dask-cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed albumentations-2.0.8 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pandas-2.3.0 scikit-learn-1.7.0 scipy-1.15.3 timm-1.0.15 torch-2.6.0 tqdm-4.67.1 transformers-4.52.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install pretrained model\n",
        "!gdown 1dZ9itDjS-h5KHc23OQb8oHqJ3KoSaPyS -O '/content/pretrained.zip'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IVU4evAFfgo",
        "outputId": "9e1c3b83-f7e8-494d-87fe-c7a9036c9a40"
      },
      "id": "1IVU4evAFfgo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1dZ9itDjS-h5KHc23OQb8oHqJ3KoSaPyS\n",
            "From (redirected): https://drive.google.com/uc?id=1dZ9itDjS-h5KHc23OQb8oHqJ3KoSaPyS&confirm=t&uuid=aa4e30b8-c10a-4bdc-a441-a2b7960d8f18\n",
            "To: /content/pretrained.zip\n",
            "100% 1.63G/1.63G [00:25<00:00, 63.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download University-1652 dataset\n",
        "!gdown 10sM4wqtNGndS7qqXspHw28mMfoFp-pl7 -O '/content/University1652.zip'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBfID0TBF7sY",
        "outputId": "87477194-a015-4903-8fbe-4abb63ed63e5"
      },
      "id": "TBfID0TBF7sY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=10sM4wqtNGndS7qqXspHw28mMfoFp-pl7\n",
            "From (redirected): https://drive.google.com/uc?id=10sM4wqtNGndS7qqXspHw28mMfoFp-pl7&confirm=t&uuid=8c355d41-8cb7-4fa0-ba04-932cecf51de1\n",
            "To: /content/University1652.zip\n",
            "100% 9.20G/9.20G [02:27<00:00, 62.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile('/content/University1652.zip', 'r') as zip_ref:\n",
        "    # Extract the contents to the /content/ directory\n",
        "    zip_ref.extractall('/content/Sample4Geo/data/')"
      ],
      "metadata": {
        "id": "XT1xTugkGpX0"
      },
      "id": "XT1xTugkGpX0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile('/content/pretrained.zip', 'r') as zip_ref:\n",
        "    # Extract the contents to the /content/ directory\n",
        "    zip_ref.extractall('/content/Sample4Geo/')"
      ],
      "metadata": {
        "id": "j0z0FpI8Gq10"
      },
      "id": "j0z0FpI8Gq10",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cd /content/\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTqGZXU_Qcws",
        "outputId": "28d0e3ea-7a51-4c16-f005-9178794919cf"
      },
      "id": "gTqGZXU_Qcws",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pretrained.zip\tSample4Geo  sample_data  University1652.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "!python ./Sample4Geo/eval_university.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sR5pn4qpJN9J",
        "outputId": "f8d37e58-65ce-4592-876b-04398060c95b"
      },
      "id": "sR5pn4qpJN9J",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model: convnext_base.fb_in22k_ft_in1k_384\n",
            "{'input_size': (3, 384, 384), 'interpolation': 'bicubic', 'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225), 'crop_pct': 1.0, 'crop_mode': 'squash'}\n",
            "Start from: /content/Sample4Geo/pretrained/university/convnext_base.fb_in22k_ft_in1k_384/weights_e1_0.9515.pth\n",
            "GPUs available: 1\n",
            "\n",
            "Image Size Query: (384, 384)\n",
            "Image Size Ground: (384, 384)\n",
            "Mean: (0.485, 0.456, 0.406)\n",
            "Std:  (0.229, 0.224, 0.225)\n",
            "\n",
            "/content/Sample4Geo/sample4geo/dataset/university.py:264: UserWarning: Argument(s) 'quality_lower, quality_upper' are not valid for transform ImageCompression\n",
            "  train_sat_transforms = A.Compose([A.ImageCompression(quality_lower=90, quality_upper=100, p=0.5),\n",
            "/content/Sample4Geo/sample4geo/dataset/university.py:266: UserWarning: Argument(s) 'always_apply' are not valid for transform ColorJitter\n",
            "  A.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.15, hue=0.15, always_apply=False, p=0.5),\n",
            "/content/Sample4Geo/sample4geo/dataset/university.py:273: UserWarning: Argument(s) 'max_holes, max_height, max_width, min_holes, min_height, min_width' are not valid for transform CoarseDropout\n",
            "  A.CoarseDropout(max_holes=25,\n",
            "/content/Sample4Geo/sample4geo/dataset/university.py:286: UserWarning: Argument(s) 'quality_lower, quality_upper' are not valid for transform ImageCompression\n",
            "  train_drone_transforms = A.Compose([A.ImageCompression(quality_lower=90, quality_upper=100, p=0.5),\n",
            "/content/Sample4Geo/sample4geo/dataset/university.py:288: UserWarning: Argument(s) 'always_apply' are not valid for transform ColorJitter\n",
            "  A.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.15, hue=0.15, always_apply=False, p=0.5),\n",
            "/content/Sample4Geo/sample4geo/dataset/university.py:295: UserWarning: Argument(s) 'max_holes, max_height, max_width, min_holes, min_height, min_width' are not valid for transform CoarseDropout\n",
            "  A.CoarseDropout(max_holes=25,\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Query Images Test: 37855\n",
            "Gallery Images Test: 951\n",
            "\n",
            "------------------------------[University-1652]------------------------------\n",
            "Extract Features:\n",
            "  0% 0/296 [00:00<?, ?it/s]/content/Sample4Geo/sample4geo/trainer.py:134: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "100% 296/296 [06:35<00:00,  1.34s/it]\n",
            "100% 8/8 [00:14<00:00,  1.82s/it]\n",
            "Compute Scores:\n",
            "100% 37855/37855 [00:18<00:00, 2026.64it/s]\n",
            "Recall@1: 92.6483 - Recall@5: 97.6859 - Recall@10: 98.2407 - Recall@top1: 98.2856 - AP: 93.8051\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "collapsed_sections": [
        "XtzZvXnzvuGB",
        "Yt9CvVqD92rb",
        "0CIR_wa4LOZF"
      ],
      "include_colab_link": true
    },
    "environment": {
      "name": "pytorch-gpu.1-9.m72",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m72"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}